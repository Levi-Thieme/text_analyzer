package jobs;

import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.StringTokenizer;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;

import org.mapdb.DB;
import org.mapdb.DBMaker;
import org.mapdb.HTreeMap;
import org.mapdb.Serializer;

import data_producer.DataProducer;

public class WordCount implements Job<Object>{
	private DataProducer producer;
	private String outputPath;
	
	public WordCount(DataProducer producer, int workers, int chunkSize, String regex, String outputPath) {
		this.producer = producer;
		this.outputPath = outputPath;
	}
	
	public Object execute() {
		producer.initialize();

		DB db = DBMaker
				.memoryDirectDB()
		        .make();
		HTreeMap<String, Long> map = db
		        .hashMap("map", Serializer.STRING, Serializer.LONG)
		        .expireMaxSize(1000)
		        .createOrOpen();
		while(producer.hasRemaining()) {
			byte[] bytes = producer.get(2048);
			String text = new String(bytes);
			StringTokenizer tokenizer = new StringTokenizer(text);
			while (tokenizer.hasMoreTokens()) {
				String token = tokenizer.nextToken();
				Long currentCount = map.get(token);
				Long total = currentCount == null ? 1 : currentCount + 1;
				map.put(token, total);
			}
		}
		producer.close();
		writeResults(outputPath, map);
		map.close();
		db.close();
		return null;
	}
	
	private void WriteResults(String path, Map results) {
		try {
			FileWriter writer = new FileWriter(path);
			
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
	}
}
